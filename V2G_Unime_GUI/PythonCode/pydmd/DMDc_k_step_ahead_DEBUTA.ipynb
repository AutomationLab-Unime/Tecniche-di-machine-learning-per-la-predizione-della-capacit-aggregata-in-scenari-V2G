{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from pydmd.plotter import plot_eigs\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot, multiply, diag, power\n",
    "from numpy import pi, exp, sin, cos\n",
    "from numpy.linalg import inv, eig, pinv, solve\n",
    "from scipy.linalg import svd, svdvals\n",
    "from math import floor, ceil # python 3.x\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from dmdc import DMDc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET DESCRIPTION:\n",
    "0 DEBUTA DATASET\n",
    "C:\\Users\\franc\\Dropbox\\Scuola\\Ruolo\\2022-23 Messina PHD\\PAPERS\\2023 DMDc in SRU Data\\Debuta\\DEBUTA DEBUTA_regressor_hankel_HDMDc.m\n",
    "\n",
    "1 SRU dataset\n",
    "    # matrix plot\n",
    "    matrix_xlabel = 'Delayed state'; matrix_ylabel = 'Time (minute)'\n",
    "    # array plot (when the plot is of one state)\n",
    "    array_xlabel = 'Time (minute)'; array_ylabel = 'State'; array_title = 'State: x_' + str(column_to_show + 1)\n",
    "\n",
    "2 Syntetic Complex dataset with complete U matrix (200 x 7160)\n",
    "3 Syntetic Complex dataset with U[161,:] (fifth input with no delay)\n",
    "    # matrix plot\n",
    "    matrix_xlabel = 'State'; matrix_ylabel = 'Samples'\n",
    "    # array plot (when the plot is of one state)\n",
    "    array_xlabel = 'Samples'; array_ylabel = 'State'; array_title = 'State: x_' + str(column_to_show + 1)\n",
    "\n",
    "4 V2G dataset with state NOT delayed and inputs NOT delayed\n",
    "5 V2G datasets with state delayed and inputs NOT delayed\n",
    "6 V2G datasets with state delayed and inputs delayed\n",
    "\n",
    "dataset = 5\n",
    "    XU1_DMDc 1 meteo + aggregated\n",
    "    XU2_DMDc 1 aggregated\n",
    "    XU3_DMDc 1 meteo (no rhum_t) + aggregated\n",
    "    XU4_DMDc 1 meteo(no rhum_t)+aggregated(no holidays)\n",
    "    XU5_DMDc 1 aggregated(no holidays)\n",
    "\n",
    "dataset = 6 \n",
    "    XU1_DMDc meteo + aggregated\n",
    "    XU2_DMDc aggregated\n",
    "    XU3_DMDc meteo (no rhum_t) + aggregated\n",
    "    XU4_DMDc meteo(no rhum_t)+aggregated(no holidays)\n",
    "    XU5_DMDc aggregated(no holidays)\n",
    "\n",
    "    # matrix plot\n",
    "    matrix_xlabel = 'Available Aggregated Capacity'; matrix_ylabel = 'Samples (30 minutes)'\n",
    "    # array plot (when the plot is of one state)\n",
    "    array_xlabel = 'Samples (30 minutes)'; array_ylabel = 'AAC'; array_title = 'State: ACC_' + str(column_to_show + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert path in wich to load .mat files\n",
    "#load the training experimental file\n",
    "#root_path = r'C:\\Users\\franc\\Dropbox\\Scuola\\Ruolo\\2022-23 Messina PHD\\V2Grid Software\\V2G-DMD\\stati ritardati ed ingressi ritardati\\Experimental Data'\n",
    "root_path=r'C:\\Users\\franc\\Dropbox\\Scuola\\Ruolo\\2022-23 Messina PHD\\PAPERS\\2023 DMDc in SRU Data\\Debuta'\n",
    "#experimental dateset number\n",
    "dataset=1\n",
    "cut_negative_AAC=False\n",
    "\n",
    "#this parameter is used to decide which column to show, 47 is the variable related to the experiment zero.\n",
    "\n",
    "\n",
    "''':param svd_rank: the rank for the truncation; If 0, the method computes the optimal rank and uses it for truncation;\n",
    " if positive interger, the method uses the argument for the truncation; if float between 0 and 1,the rank is the number \n",
    " of the biggest singular values that are needed to reach the 'energy' specified by `svd_rank`; if -1, the method does\n",
    "not compute truncation.'''\n",
    "\n",
    "\n",
    "#sampling time \n",
    "sampling_time_minutes = 6 #6 minuti\n",
    "\n",
    "x_lag_samples=12\n",
    "u_lag_samples=12\n",
    "prediction_k_minutes = 12\n",
    "normalization=True\n",
    "svd_rank_set_p = 66\n",
    "svd_rank_set_r = 10\n",
    "#prediction step in minutes\n",
    "\n",
    "x_lag_minutes=x_lag_samples*sampling_time_minutes\n",
    "u_lag_minutes=u_lag_samples*sampling_time_minutes\n",
    "prediction_k=math.floor(prediction_k_minutes//sampling_time_minutes)\n",
    "\n",
    "\n",
    "if normalization==True:\n",
    "    norm_string='_norm'\n",
    "else:\n",
    "    norm_string=''\n",
    "\n",
    "\n",
    "#path_for_load_experimental_train = root_path+  r'\\Train\\XU' + str(dataset)+'train_DMDc.mat'\n",
    "path_for_load_experimental_train = root_path+  r'\\DEBUTA_XU_training_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat'\n",
    "\n",
    "#load the test experimental file\n",
    "#path_for_load_experimental_valid = root_path+  r'\\valid\\XU' + str(dataset)+'valid_DMDc.mat'\n",
    "path_for_load_experimental_test = root_path+  r'\\DEBUTA_XU_test_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat'\n",
    "path_for_load_experimental_valid = root_path+  r'\\DEBUTA_XU_validation_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat'\n",
    "\n",
    "if svd_rank_set_p>-1:\n",
    "    svd_p_string=\"_svdp_\"+str(svd_rank_set_p)\n",
    "else:\n",
    "    svd_p_string=''\n",
    "\n",
    "#insert path in which to  save the csv files \n",
    "#save the training reconstructed file\n",
    "path_for_save_reconstructed_train =  root_path+  r'\\DEBUTA_training_Prediction_'+str(prediction_k_minutes)+'min_svdrank_'+str(svd_rank_set_r)+svd_p_string+'_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat.csv'\n",
    "\n",
    "#join ->    _reconstructed_train.csv\n",
    "#save the test reconstructed file\n",
    "#path_for_save_reconstructed_test = root_path+  r'\\Test\\XU' + str(dataset)+'test_DMDc_rank_'+str(svd_rank_set)+'_reconstructed_XU' + str(dataset)+'predict_'+str(prediction_k_minutes)+'h.csv'\n",
    "#path_for_save_experimental_test =  root_path+  r'\\Test\\XU' + str(dataset)+'test_DMDc_experimental_XU' + str(dataset)+'predict_'+str(prediction_k_minutes)+'h.csv'\n",
    "path_for_save_reconstructed_test = root_path+  r'\\DEBUTA_test_Prediction_'+str(prediction_k_minutes)+'min_svdrank_'+str(svd_rank_set_r)+svd_p_string+'_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat.csv'\n",
    "\n",
    "\n",
    "path_for_save_reconstructed_valid = root_path+  r'\\DEBUTA_validation_Prediction_'+str(prediction_k_minutes)+'min_svdrank_'+str(svd_rank_set_r)+svd_p_string+'_delay_minute_x'+str(x_lag_minutes)+'_u'+str(u_lag_minutes)+'_HDMDc'+str(norm_string)+'.mat.csv'\n",
    "\n",
    "#join ->    _reconstructed_test.csv                \n",
    "\n",
    "\n",
    "# matrix plot\n",
    "matrix_xlabel = 'y - C4 in C5 (%)'\n",
    "matrix_ylabel = 'Samples (6 minutes)'\n",
    "\n",
    "# array plot (when the plot is of one state)\n",
    "array_xlabel = 'Samples (6 minutes)'\n",
    "array_ylabel = '%'\n",
    "array_title = 'Predicted y - C4 in C5 (%) at ' + str(prediction_k_minutes)+'h'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Load Training Data"
    ]
   },
   "source": [
    "LOAD DATASET FOR TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "TRAINING"
    ]
   },
   "source": [
    "Load Dataset For Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for traininig\n",
    "D_mat = scipy.io.loadmat(path_for_load_experimental_train)\n",
    "D_mat_list = [[element for element in upperElement] for upperElement in D_mat['X']]\n",
    "U_mat_list = [[element for element in upperElement] for upperElement in D_mat['U']]\n",
    "D_train = np.array(D_mat_list)\n",
    "U_train = np.array(U_mat_list)\n",
    "\n",
    "column_to_show = D_train.shape[0]-1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT Settings, scale normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from this moment on, nothing needs to be set'''\n",
    "\n",
    "#if the data are an array 1-D with this instruction they became 2-D\n",
    "if len(D_train.shape) == 1:\n",
    "    D_train = D_train[: , np.newaxis].T\n",
    "if len(U_train.shape) == 1:\n",
    "    U_train = U_train[: , np.newaxis].T\n",
    "\n",
    "vmax = np.amax(D_train)\n",
    "vmin = np.amin(D_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#eventually matrix D_train or U_train have different dimensions of columns (snapshots)\n",
    "if D_train.shape[1] > U_train.shape[1]:\n",
    "    D_train = D_train[:,:U_train.shape[1]]\n",
    "else:\n",
    "    U_train = U_train[:,:D_train.shape[1]]\n",
    "\n",
    "#eventually matricies D_train or U_train have different dimensions of columns (snapshots) and different dimension from Test matricies\n",
    "#if path_for_load_experimental_test is not None:\n",
    "#    if D_test.shape[1] > U_test.shape[1]:\n",
    "#        D_test = D_test[:,:U_test.shape[1]]\n",
    "#        max = U_test.shape[1]\n",
    "#    else:\n",
    "#        U_test = U_test[:,:D_test.shape[1]]\n",
    "#        max = D_test.shape[1]\n",
    "\n",
    "#    D_train = D_train[:,:max]\n",
    "#    U_train = U_train[:,:max]\n",
    "\n",
    "\n",
    "\n",
    "#number of rows of the dataset\n",
    "x_train = np.linspace(0, D_train.shape[0], D_train.shape[0])\n",
    "\n",
    "#number of columns of the dataset\n",
    "t_train = np.linspace(0, D_train.shape[1], D_train.shape[1])\n",
    "\n",
    "\n",
    "#this function allow to make plot like image (it is used to plot matrix values)\n",
    "def make_plot(X, x=None, y=None, title='', xlabel = None, ylabel = None, vmin = None, vmax = None, ticks = None):\n",
    "    \"\"\"\n",
    "    Plot of the data X\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if vmin is not None:\n",
    "        CS = plt.pcolormesh(x, y, X, vmin = vmin, vmax = vmax, cmap= \"viridis\")\n",
    "    else:\n",
    "        plt.pcolor(X.real)\n",
    "    plt.colorbar()\n",
    "    if ticks is not None:\n",
    "        plt.xticks(np.arange(0, len(X[0]), ticks))\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "#make_plot(D_train.T, x=x_train, y=t_train, title = 'Training dataset', xlabel = matrix_xlabel, ylabel = matrix_ylabel)\n",
    "\n",
    "\n",
    "#plot of the state of the dataset selected\n",
    "plt.figure()\n",
    "#valid if considering column_toshow=47\n",
    "xx=0\n",
    "while column_to_show-xx>0:\n",
    "    plt.plot( D_train[column_to_show-xx,0:column_to_show*2], 'k', label=r'$X_{t_0 -'+ str(xx) + r'}$')\n",
    "    xx+=1\n",
    "plt.title(array_title)\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel(array_ylabel)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dmdc.DMDc at 0x1a10cfcf070>"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_train = U_train[:,1:]\n",
    "\n",
    "dmdc = DMDc(svd_rank = svd_rank_set_r, svd_rank_omega=svd_rank_set_p)    \n",
    "\n",
    "dmdc.fit(D_train,U_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-STEP-HAED Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DMDc_train_reconstructed = []\n",
    "#DMDc_train_reconstructed_dayahead = []\n",
    "\n",
    "#prediction_slots = math.floor(D_train.shape[1] // prediction_k)\n",
    "\n",
    "for k in range(0, D_train.shape[1]-prediction_k-1):\n",
    "    D_slot = D_train[: ,k:k+prediction_k-1]\n",
    "    U_slot = U_train[: ,k:k+prediction_k-1]\n",
    "    \n",
    "    #zero_padding_lenght = int(U_train.shape[1] - U_slot.shape[1])\n",
    "    #zeros_matrix_D = np.zeros([D_train.shape[0], zero_padding_lenght])\n",
    "    #zeros_matrix_U = np.zeros([U_train.shape[0], zero_padding_lenght])\n",
    "    #D_slot = np.hstack([D_slot, zeros_matrix_D])\n",
    "    #U_slot = np.hstack([U_slot, zeros_matrix_U])\n",
    "    reconstructed_slot = dmdc.reconstructed_data(open_loop = False, X = D_slot, control_input = U_slot, cut_negative_AAC=cut_negative_AAC)\n",
    "    reconstructed_slot =reconstructed_slot.real \n",
    "    #reconstructed_slot_dayahead =reconstructed_slot_complete[:,prediction_k+1:2*prediction_k+1].real \n",
    "    DMDc_train_reconstructed.append(reconstructed_slot[column_to_show,-1])\n",
    "    #DMDc_train_reconstructed_dayahead.append(reconstructed_slot_dayahead)\n",
    "\n",
    "DMDc_train_reconstructed = np.hstack(DMDc_train_reconstructed)\n",
    "#DMDc_train_reconstructed_dayahead = np.hstack(DMDc_train_reconstructed_dayahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUG windwow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14580916,  0.04115234, -0.05091957, ..., -0.11325739,\n",
       "       -0.10738925, -0.13257309])"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMDc_train_reconstructed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELABORATE TRAINING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train KPI: 12min, x_lag=72min\n",
      "MSE: signal\n",
      "0.0032692847604774843\n",
      "3.27e-03\n",
      "MAPE: signal\n",
      "0.35682047029551645\n",
      "3.57e-01\n",
      "MAE: signal\n",
      "0.03553219621560271\n",
      "3.55e-02\n",
      "RMSE: signal\n",
      "0.05717765962749336\n",
      "5.72e-02\n",
      "R2: signal\n",
      "0.9967109410446281\n",
      "9.97e-01\n"
     ]
    }
   ],
   "source": [
    "# troncamento per adattarsi al fatto che la divisione in slot potrebbe lasciare fuori qualcosa\n",
    "#prendo solo il t_0, e parto dal ritardo 48 campioni per la previsione\n",
    "D_train_truncated = D_train[column_to_show,:DMDc_train_reconstructed.shape[0]-prediction_k]\n",
    "DMDc_train_reconstructed_comparison=DMDc_train_reconstructed[:-prediction_k]\n",
    "\n",
    "#extraction of the matrix A calculation taken from the method reconstruction_data\n",
    "eigs = np.power(dmdc.eigs, dmdc.dmd_time[\"dt\"] // dmdc.original_time[\"dt\"])\n",
    "A = np.linalg.multi_dot([dmdc.modes, np.diag(eigs), np.linalg.pinv(dmdc.modes)])\n",
    "\n",
    "#t_train = t_train[:DMDc_train_reconstructed.shape[1]]\n",
    "\n",
    "y_true=D_train_truncated\n",
    "y_pred=DMDc_train_reconstructed_comparison\n",
    "\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "plt.plot(y_true, 'b', label='Experimental training data')\n",
    "#plt.plot(t_train, DMDc_train_reconstructed[column_to_show,:].real, 'g', label='DMDc reconstructed training data')\n",
    "plt.plot(y_pred, 'g', label='DMDc reconstructed training data')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel(array_ylabel)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''''\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "plt.plot(DMDc_train_reconstructed_dayahead[column_to_show,:].real, 'g', label='DMDc reconstructed training data day ahead')\n",
    "plt.plot(D_train_truncated[column_to_show,prediction_k+1:].real, 'b', label='Experimental training data')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel(array_ylabel)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "\n",
    "\n",
    "error=np.array(y_true) - np.array(y_pred)\n",
    "plt.plot(error, 'b', label='Error')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    mse_value = mean_squared_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mse_value\n",
    "\n",
    "def MAPE (y_true,y_pred):   #MEAN ABSOLUTE PERCENTAGE ERROR\n",
    "    mape = mean_absolute_percentage_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mape\n",
    "\n",
    "def MAE(y_true, y_pred):     #MEAN ABSOLUTE ERROR\n",
    "    mae_value = mean_absolute_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mae_value\n",
    "\n",
    "def RMSE(y_true, y_pred):     #ROOT MEAN SQUARED ERROR\n",
    "    rmse_value = math.sqrt(MSE(y_true.real, y_pred.real))\n",
    "    return rmse_value\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    r2_value = r2_score(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return r2_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train KPI: \"+str(prediction_k_minutes)+\"min, x_lag=\"+str(x_lag_minutes)+\"min\")\n",
    "#print(\"MSE: matrix\")\n",
    "#print((MSE(DMDc_train_reconstructed.T,D_train_truncated.real.T)))\n",
    "#print(\"{:.2e}\".format(MSE(DMDc_train_reconstructed.T , D_train_truncated.real.T)))\n",
    "print(\"MSE: signal\")\n",
    "print((MSE(y_pred,y_true)))\n",
    "print(\"{:.2e}\".format(MSE(y_pred,y_true)))\n",
    "\n",
    "#print (\"MAPE: \")\n",
    "#print (MAPE(DMDc_train_reconstructed.T , D_train_truncated.real.T))\n",
    "#print(\"{:.2e}\".format(MAPE(DMDc_train_reconstructed.T , D_train_truncated.real.T)))\n",
    "print(\"MAPE: signal\")\n",
    "print((MAPE(y_pred,y_true)))\n",
    "print(\"{:.2e}\".format(MAPE(y_pred,y_true)))\n",
    "\n",
    "#print (\"MAE: \")\n",
    "#print(MAE(DMDc_train_reconstructed.T , D_train_truncated.real.T))\n",
    "#print(\"{:.2e}\".format(MAE(DMDc_train_reconstructed.T , D_train_truncated.real.T)))\n",
    "print(\"MAE: signal\")\n",
    "print((MAE(y_pred,y_true)))\n",
    "print(\"{:.2e}\".format(MAE(y_pred,y_true)))\n",
    "\n",
    "#print (\"RMSE: \")\n",
    "#print(RMSE(DMDc_train_reconstructed.T , D_train_truncated.real.T))\n",
    "#print(\"{:.2e}\".format(RMSE(DMDc_train_reconstructed.T , D_train_truncated.real.T)))\n",
    "print(\"RMSE: signal\")\n",
    "print((RMSE(y_pred,y_true)))\n",
    "print(\"{:.2e}\".format(RMSE(y_pred,y_true)))\n",
    "\n",
    "#print (\"R2: \")\n",
    "#print(R2(DMDc_train_reconstructed.T , D_train_truncated.real.T))\n",
    "#print(\"{:.2e}\".format(R2(DMDc_train_reconstructed.T , D_train_truncated.real.T)))\n",
    "print(\"R2: signal\")\n",
    "print((R2(y_pred,y_true)))\n",
    "print(\"{:.2e}\".format(R2(y_pred,y_true)))\n",
    "\n",
    "#show A and B of the model\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Matrix A')\n",
    "plt.pcolor(A.real)\n",
    "plt.colorbar()\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Output')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Matrix B')\n",
    "plt.pcolor(dmdc.B)\n",
    "plt.colorbar()\n",
    "plt.xticks(np.linspace(0, dmdc.B.shape[1], (U_train.shape[0] // D_train.shape[0]) + 1))\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITING CSV with TRAINING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def writing_csv(path, data):\n",
    "    with open(path, 'w', newline='') as file_csv:\n",
    "        writer = csv.writer(file_csv)\n",
    "        writer.writerows(data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Experimental'] = y_true\n",
    "df['Reconstructed'] = y_pred\n",
    "df.to_csv(path_for_save_reconstructed_train, sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Step Ahead TEST Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for testing\n",
    "#if path_for_load_experimental_test is not None:\n",
    "   \n",
    "    #if the data are an array 1-D with this instruction they became 2-D\n",
    "#    if len(D_test.shape) == 1:\n",
    "#        D_test = D_test[:, np.newaxis].T\n",
    "#   if len(U_test.shape) == 1:\n",
    "#        U_test = U_test[:, np.newaxis].T\n",
    "\n",
    "'''Test of the model'''\n",
    "#dataset for testing\n",
    "if path_for_load_experimental_test is not None:\n",
    "    D_mat = scipy.io.loadmat(path_for_load_experimental_test)\n",
    "\n",
    "    D_mat_list = [[element for element in upperElement] for upperElement in D_mat['X']]\n",
    "    U_mat_list = [[element for element in upperElement] for upperElement in D_mat['U']]\n",
    "\n",
    "    D_test = np.array(D_mat_list)\n",
    "    U_test = np.array(U_mat_list)\n",
    "\n",
    "\n",
    "vmin = np.amax(D_test)\n",
    "vmax = np.amin(D_test)\n",
    "\n",
    "U_test = U_test[:,1:]\n",
    "\n",
    "\n",
    "DMDc_test_reconstructed = []\n",
    "\n",
    "for k in range(0, D_test.shape[1]-prediction_k-1):\n",
    "    D_slot = D_test[: ,k:k+prediction_k-1]\n",
    "    U_slot = U_test[: ,k:k+prediction_k-1]\n",
    "    reconstructed_slot = dmdc.reconstructed_data(open_loop = False, X = D_slot, control_input = U_slot, cut_negative_AAC=cut_negative_AAC)\n",
    "    reconstructed_slot =reconstructed_slot.real \n",
    "    DMDc_test_reconstructed.append(reconstructed_slot[column_to_show,-1])\n",
    "   \n",
    "\n",
    "DMDc_test_reconstructed = np.hstack(DMDc_test_reconstructed)\n",
    "\n",
    "\n",
    "\n",
    "    # comparison between experimental test and reconstructed test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Test Results"
    ]
   },
   "source": [
    "ELABORATE TEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test KPI: 12min, x_lag=72min\n",
      "MSE: signal\n",
      "0.0027146244823767025\n",
      "2.71e-03\n",
      "MAPE: signal\n",
      "0.3777726324081075\n",
      "3.78e-01\n",
      "MAE: signal\n",
      "0.03734182196798622\n",
      "3.73e-02\n",
      "RMSE: signal\n",
      "0.05210205833147768\n",
      "5.21e-02\n",
      "R2: signal\n",
      "0.9971851250832016\n",
      "9.97e-01\n"
     ]
    }
   ],
   "source": [
    "# troncamento per adattarsi al fatto che la divisione in slot potrebbe lasciare fuori qualcosa\n",
    "#prendo solo il t_0, e parto dal ritardo 48 campioni per la previsione\n",
    "D_test_truncated = D_test[column_to_show,:DMDc_test_reconstructed.shape[0]-prediction_k]\n",
    "DMDc_test_reconstructed_comparison=DMDc_test_reconstructed[:-prediction_k]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "\n",
    "y_test_true=D_test_truncated\n",
    "y_test_pred=DMDc_test_reconstructed_comparison\n",
    "error=np.array(y_test_true) - np.array(y_test_pred)\n",
    "plt.plot(error, 'b', label='Error')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "plt.plot(y_test_true, 'b', label='Experimental test data')\n",
    "plt.plot(y_test_pred, 'g', label='DMDc reconstructed test data')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel(array_ylabel)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    mse_value = mean_squared_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mse_value\n",
    "\n",
    "def MAPE (y_true,y_pred):   #MEAN ABSOLUTE PERCENTAGE ERROR\n",
    "    mape = mean_absolute_percentage_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mape\n",
    "\n",
    "def MAE(y_true, y_pred):     #MEAN ABSOLUTE ERROR\n",
    "    mae_value = mean_absolute_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mae_value\n",
    "\n",
    "def RMSE(y_true, y_pred):     #ROOT MEAN SQUARED ERROR\n",
    "    rmse_value = math.sqrt(MSE(y_true.real, y_pred.real))\n",
    "    return rmse_value\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    r2_value = r2_score(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return r2_value\n",
    "\n",
    "\n",
    "print(\"Test KPI: \"+str(prediction_k_minutes)+\"min, x_lag=\"+str(x_lag_minutes)+\"min\")\n",
    "print(\"MSE: signal\")\n",
    "print((MSE(y_test_pred,y_test_true)))\n",
    "print(\"{:.2e}\".format(MSE(y_test_pred,y_test_true)))\n",
    "\n",
    "#print (\"MAPE: \")\n",
    "print(\"MAPE: signal\")\n",
    "print((MAPE(y_test_pred,y_test_true)))\n",
    "print(\"{:.2e}\".format(MAPE(y_test_pred,y_test_true)))\n",
    "\n",
    "#print (\"MAE: \")\n",
    "print(\"MAE: signal\")\n",
    "print((MAE(y_test_pred,y_test_true)))\n",
    "print(\"{:.2e}\".format(MAE(y_test_pred,y_test_true)))\n",
    "\n",
    "#print (\"RMSE: \")\n",
    "print(\"RMSE: signal\")\n",
    "print((RMSE(y_test_pred,y_test_true)))\n",
    "print(\"{:.2e}\".format(RMSE(y_test_pred,y_test_true)))\n",
    "\n",
    "#print (\"R2: \")\n",
    "\n",
    "print(\"R2: signal\")\n",
    "print((R2(y_test_pred,y_test_true)))\n",
    "print(\"{:.2e}\".format(R2(y_test_pred,y_test_true)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write TEST RESULTS on CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_csv(path, data):\n",
    "    with open(path, 'w', newline='') as file_csv:\n",
    "        writer = csv.writer(file_csv)\n",
    "        writer.writerows(data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Experimental'] = y_test_true\n",
    "df['Reconstructed'] = y_test_pred\n",
    "df.to_csv(path_for_save_reconstructed_test, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for testing\n",
    "#if path_for_load_experimental_test is not None:\n",
    "   \n",
    "    #if the data are an array 1-D with this instruction they became 2-D\n",
    "#    if len(D_test.shape) == 1:\n",
    "#        D_test = D_test[:, np.newaxis].T\n",
    "#   if len(U_test.shape) == 1:\n",
    "#        U_test = U_test[:, np.newaxis].T\n",
    "\n",
    "'''Test of the model'''\n",
    "#dataset for testing\n",
    "if path_for_load_experimental_valid is not None:\n",
    "    D_mat = scipy.io.loadmat(path_for_load_experimental_valid)\n",
    "\n",
    "    D_mat_list = [[element for element in upperElement] for upperElement in D_mat['X']]\n",
    "    U_mat_list = [[element for element in upperElement] for upperElement in D_mat['U']]\n",
    "\n",
    "    D_valid = np.array(D_mat_list)\n",
    "    U_valid = np.array(U_mat_list)\n",
    "\n",
    "\n",
    "vmin = np.amax(D_valid)\n",
    "vmax = np.amin(D_valid)\n",
    "\n",
    "U_valid = U_valid[:,1:]\n",
    "\n",
    "\n",
    "DMDc_valid_reconstructed = []\n",
    "\n",
    "for k in range(0, D_valid.shape[1]-prediction_k-1):\n",
    "    D_slot = D_valid[: ,k:k+prediction_k-1]\n",
    "    U_slot = U_valid[: ,k:k+prediction_k-1]\n",
    "    reconstructed_slot = dmdc.reconstructed_data(open_loop = False, X = D_slot, control_input = U_slot, cut_negative_AAC=cut_negative_AAC)\n",
    "    reconstructed_slot =reconstructed_slot.real \n",
    "    DMDc_valid_reconstructed.append(reconstructed_slot[column_to_show,-1])\n",
    "   \n",
    "\n",
    "DMDc_valid_reconstructed = np.hstack(DMDc_valid_reconstructed)\n",
    "\n",
    "# comparison between experimental test and reconstructed valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elaborate Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation KPI: 12min, x_lag=72min\n",
      "MSE: signal\n",
      "0.005022442950727632\n",
      "5.02e-03\n",
      "MAPE: signal\n",
      "0.31460649591533607\n",
      "3.15e-01\n",
      "MAE: signal\n",
      "0.04804414787420069\n",
      "4.80e-02\n",
      "RMSE: signal\n",
      "0.07086919606378805\n",
      "7.09e-02\n",
      "R2: signal\n",
      "0.9949571389717924\n",
      "9.95e-01\n"
     ]
    }
   ],
   "source": [
    "# troncamento per adattarsi al fatto che la divisione in slot potrebbe lasciare fuori qualcosa\n",
    "#prendo solo il t_0, e parto dal ritardo 48 campioni per la previsione\n",
    "D_valid_truncated = D_valid[column_to_show,:DMDc_valid_reconstructed.shape[0]-prediction_k]\n",
    "DMDc_valid_reconstructed_comparison=DMDc_valid_reconstructed[:-prediction_k]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "\n",
    "y_valid_true=D_valid_truncated\n",
    "y_valid_pred=DMDc_valid_reconstructed_comparison\n",
    "error=np.array(y_valid_true) - np.array(y_valid_pred)\n",
    "plt.plot(error, 'b', label='Error')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(array_title)\n",
    "plt.plot(y_valid_true, 'b', label='Experimental validation data')\n",
    "plt.plot(y_valid_pred, 'g', label='DMDc reconstructed validation data')\n",
    "plt.xlabel(array_xlabel)\n",
    "plt.ylabel(array_ylabel)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    mse_value = mean_squared_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mse_value\n",
    "\n",
    "def MAPE (y_true,y_pred):   #MEAN ABSOLUTE PERCENTAGE ERROR\n",
    "    mape = mean_absolute_percentage_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mape\n",
    "\n",
    "def MAE(y_true, y_pred):     #MEAN ABSOLUTE ERROR\n",
    "    mae_value = mean_absolute_error(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return mae_value\n",
    "\n",
    "def RMSE(y_true, y_pred):     #ROOT MEAN SQUARED ERROR\n",
    "    rmse_value = math.sqrt(MSE(y_true.real, y_pred.real))\n",
    "    return rmse_value\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    r2_value = r2_score(np.array(y_true.real), np.array(y_pred.real))\n",
    "    return r2_value\n",
    "\n",
    "\n",
    "print(\"Validation KPI: \"+str(prediction_k_minutes)+\"min, x_lag=\"+str(x_lag_minutes)+\"min\")\n",
    "print(\"MSE: signal\")\n",
    "print((MSE(y_valid_pred,y_valid_true)))\n",
    "print(\"{:.2e}\".format(MSE(y_valid_pred,y_valid_true)))\n",
    "\n",
    "#print (\"MAPE: \")\n",
    "print(\"MAPE: signal\")\n",
    "print((MAPE(y_valid_pred,y_valid_true)))\n",
    "print(\"{:.2e}\".format(MAPE(y_valid_pred,y_valid_true)))\n",
    "\n",
    "#print (\"MAE: \")\n",
    "print(\"MAE: signal\")\n",
    "print((MAE(y_valid_pred,y_valid_true)))\n",
    "print(\"{:.2e}\".format(MAE(y_valid_pred,y_valid_true)))\n",
    "\n",
    "#print (\"RMSE: \")\n",
    "print(\"RMSE: signal\")\n",
    "print((RMSE(y_valid_pred,y_valid_true)))\n",
    "print(\"{:.2e}\".format(RMSE(y_valid_pred,y_valid_true)))\n",
    "\n",
    "#print (\"R2: \")\n",
    "\n",
    "print(\"R2: signal\")\n",
    "print((R2(y_valid_pred,y_valid_true)))\n",
    "print(\"{:.2e}\".format(R2(y_valid_pred,y_valid_true)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Validation data on CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_csv(path, data):\n",
    "    with open(path, 'w', newline='') as file_csv:\n",
    "        writer = csv.writer(file_csv)\n",
    "        writer.writerows(data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Experimental'] = y_valid_true\n",
    "df['Reconstructed'] = y_valid_pred\n",
    "df.to_csv(path_for_save_reconstructed_valid, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Notebook_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
